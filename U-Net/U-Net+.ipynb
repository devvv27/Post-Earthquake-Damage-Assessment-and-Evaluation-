{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12844889,"sourceType":"datasetVersion","datasetId":8124093}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"3c934121","cell_type":"markdown","source":"# U-Net+ Change Detection Training Notebook\nThis notebook trains a U-Net+ model for change detection using A/B/label folders for train, val, and test. U-Net+ is a simplified variant with enhanced skip connections.","metadata":{}},{"id":"31c3e029","cell_type":"markdown","source":"## Assignment Compliance (Segmentation)\n- Problem: Change detection (binary segmentation of change mask)\n- Model: U-Net+ (variant with enhanced skip connections)\n- Epochs: Min 50 with early stopping (patience 10)\n- Data: Using existing train / val / test folders exactly as provided (no re-splitting enforced).\n- Metrics tracked: IoU, Dice, Precision, Recall, F1, Accuracy, Loss + confusion matrix (pixel-wise)\n- Outputs: Metric plots, sample predictions, parameter count, saved best weights.\n- Saved artifacts: best_model.pth, training_history.csv, test_metrics.csv, confusion_matrix.txt, prediction PNGs.","metadata":{}},{"id":"21160e8f","cell_type":"code","source":"# Install all required packages\n!pip install torch torchvision scikit-learn pandas tqdm matplotlib seaborn pillow --quiet","metadata":{},"outputs":[],"execution_count":null},{"id":"2d531a9a","cell_type":"code","source":"# Imports & Setup\nimport os, random\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Device & Reproducibility\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\nprint(f\"Using device: {DEVICE}\")\n\n# Loss components (Dice + BCE)\nclass DiceLoss(nn.Module):\n    def __init__(self, smooth=1e-6):\n        super().__init__()\n        self.smooth = smooth\n    def forward(self, preds, targets):\n        preds = preds.contiguous()\n        targets = targets.contiguous()\n        intersection = (preds * targets).sum(dim=(2,3))\n        denom = preds.sum(dim=(2,3)) + targets.sum(dim=(2,3))\n        dice = (2 * intersection + self.smooth) / (denom + self.smooth)\n        return 1 - dice.mean()\n\ndef combined_loss(logits, targets, bce_w=0.6, dice_w=0.4):\n    bce = nn.BCEWithLogitsLoss()(logits, targets)\n    probs = torch.sigmoid(logits)\n    dloss = DiceLoss()(probs, targets)\n    return bce_w * bce + dice_w * dloss\n\n@torch.no_grad()\ndef batch_metrics(logits, targets, thresh=0.5):\n    probs = torch.sigmoid(logits)\n    preds = (probs >= thresh).float()\n    p = preds.view(-1).cpu().numpy()\n    t = targets.view(-1).cpu().numpy()\n    cm = confusion_matrix(t, p, labels=[0,1]) if (t.sum()>0 or p.sum()>0) else np.array([[len(t),0],[0,0]])\n    if cm.shape == (2,2):\n        tn, fp, fn, tp = cm.ravel()\n    else:\n        tn = fp = fn = tp = 0\n    eps = 1e-8\n    iou = tp / (tp + fp + fn + eps)\n    dice = (2*tp) / (2*tp + fp + fn + eps)\n    precision = tp / (tp + fp + eps) if (tp+fp)>0 else 0.0\n    recall = tp / (tp + fn + eps) if (tp+fn)>0 else 0.0\n    f1 = 2*precision*recall/(precision+recall+eps) if (precision+recall)>0 else 0.0\n    acc = (tp + tn) / (tp + tn + fp + fn + eps)\n    return dict(tp=int(tp), fp=int(fp), fn=int(fn), tn=int(tn), iou=float(iou), dice=float(dice), precision=float(precision), recall=float(recall), f1=float(f1), acc=float(acc))\n\nclass EarlyStopping:\n    def __init__(self, patience=10, min_delta=1e-4, restore_best=True):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.restore_best = restore_best\n        self.best_loss = None\n        self.counter = 0\n        self.best_state = None\n    def __call__(self, epoch, current_loss, model):\n        if self.best_loss is None or (self.best_loss - current_loss) > self.min_delta:\n            self.best_loss = current_loss\n            self.counter = 0\n            if self.restore_best:\n                self.best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n        else:\n            self.counter += 1\n        if self.counter >= self.patience:\n            if self.restore_best and self.best_state is not None:\n                model.load_state_dict(self.best_state)\n            return True\n        return False","metadata":{},"outputs":[],"execution_count":null},{"id":"91ac8ade","cell_type":"code","source":"# Dataset\nDATA_ROOT = '/kaggle/input/finaldatasetnew/earthquakedatasetnew'  # Kaggle dataset path\nIMG_SIZE = (256, 256)\nTRAIN_BATCH = 6\nVAL_BATCH = 2\nTEST_BATCH = 1\n\ntransform_img = transforms.Compose([\n    transforms.Resize(IMG_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\n\ntransform_mask = transforms.Compose([\n    transforms.Resize(IMG_SIZE),\n    transforms.ToTensor()\n])\n\nclass ChangeDataset(Dataset):\n    def __init__(self, root, split='train'):\n        if split=='train':\n            a_dir = os.path.join(root,'train','A_train_aug')\n            b_dir = os.path.join(root,'train','B_train_aug')\n            m_dir = os.path.join(root,'train','label_train_aug')\n        elif split=='val':\n            a_dir = os.path.join(root,'val','A_val')\n            b_dir = os.path.join(root,'val','B_val')\n            m_dir = os.path.join(root,'val','label_val')\n        else:\n            a_dir = os.path.join(root,'test','A_test')\n            b_dir = os.path.join(root,'test','B_test')\n            m_dir = os.path.join(root,'test','label_test')\n        self.a_files = sorted([f for f in os.listdir(a_dir) if f.endswith('.png')])\n        self.a_dir, self.b_dir, self.m_dir = a_dir, b_dir, m_dir\n    def __len__(self): return len(self.a_files)\n    def __getitem__(self, idx):\n        name = self.a_files[idx]\n        a = Image.open(os.path.join(self.a_dir,name)).convert('RGB')\n        b = Image.open(os.path.join(self.b_dir,name)).convert('RGB')\n        m = Image.open(os.path.join(self.m_dir,name)).convert('L')\n        a = transform_img(a)\n        b = transform_img(b)\n        m = transform_mask(m)\n        m = (m>0.5).float()\n        x = torch.cat([a,b], dim=0)\n        return x, m\n\ntrain_ds = ChangeDataset(DATA_ROOT,'train')\nval_ds = ChangeDataset(DATA_ROOT,'val')\ntest_ds = ChangeDataset(DATA_ROOT,'test')\n\ntrain_loader = DataLoader(train_ds, batch_size=TRAIN_BATCH, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_ds, batch_size=VAL_BATCH, shuffle=False, num_workers=0)\ntest_loader = DataLoader(test_ds, batch_size=TEST_BATCH, shuffle=False, num_workers=0)\n\nprint(f\"Train {len(train_ds)} | Val {len(val_ds)} | Test {len(test_ds)}\")","metadata":{},"outputs":[],"execution_count":null},{"id":"0c35dc3b","cell_type":"code","source":"# U-Net+ Implementation (Enhanced Skip Connections)\nclass ConvBlock(nn.Module):\n    def __init__(self, in_ch, out_ch, dropout_rate=0.15):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_ch)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.dropout1 = nn.Dropout2d(dropout_rate) if dropout_rate > 0 else nn.Identity()\n        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_ch)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.dropout2 = nn.Dropout2d(dropout_rate) if dropout_rate > 0 else nn.Identity()\n    \n    def forward(self, x):\n        x = self.relu1(self.bn1(self.conv1(x)))\n        x = self.dropout1(x)\n        x = self.relu2(self.bn2(self.conv2(x)))\n        x = self.dropout2(x)\n        return x\n\nclass AttentionGate(nn.Module):\n    \"\"\"Attention mechanism for skip connections\"\"\"\n    def __init__(self, F_g, F_l, F_int):\n        super().__init__()\n        self.W_g = nn.Sequential(\n            nn.Conv2d(F_g, F_int, 1, bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n        self.W_x = nn.Sequential(\n            nn.Conv2d(F_l, F_int, 1, bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, 1, bias=True),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n        self.relu = nn.ReLU(inplace=True)\n    \n    def forward(self, g, x):\n        g1 = self.W_g(g)\n        x1 = self.W_x(x)\n        psi = self.relu(g1 + x1)\n        psi = self.psi(psi)\n        return x * psi\n\nclass UNetPlus(nn.Module):\n    \"\"\"U-Net+ with Attention Gates\"\"\"\n    def __init__(self, in_ch=6, out_ch=1, filters=(32,64,128,256,512)):\n        super().__init__()\n        f = filters\n        \n        # Encoder\n        self.enc1 = ConvBlock(in_ch, f[0], dropout_rate=0.0)\n        self.enc2 = ConvBlock(f[0], f[1], dropout_rate=0.0)\n        self.enc3 = ConvBlock(f[1], f[2], dropout_rate=0.1)\n        self.enc4 = ConvBlock(f[2], f[3], dropout_rate=0.1)\n        self.bottleneck = ConvBlock(f[3], f[4], dropout_rate=0.15)\n        \n        self.pool = nn.MaxPool2d(2)\n        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        \n        # Attention gates\n        self.att4 = AttentionGate(F_g=f[4], F_l=f[3], F_int=f[3]//2)\n        self.att3 = AttentionGate(F_g=f[3], F_l=f[2], F_int=f[2]//2)\n        self.att2 = AttentionGate(F_g=f[2], F_l=f[1], F_int=f[1]//2)\n        self.att1 = AttentionGate(F_g=f[1], F_l=f[0], F_int=f[0]//2)\n        \n        # Decoder\n        self.dec4 = ConvBlock(f[4] + f[3], f[3], dropout_rate=0.15)\n        self.dec3 = ConvBlock(f[3] + f[2], f[2], dropout_rate=0.15)\n        self.dec2 = ConvBlock(f[2] + f[1], f[1], dropout_rate=0.15)\n        self.dec1 = ConvBlock(f[1] + f[0], f[0], dropout_rate=0.15)\n        \n        self.final = nn.Conv2d(f[0], out_ch, 1)\n    \n    def forward(self, x):\n        # Encoder\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        e4 = self.enc4(self.pool(e3))\n        b = self.bottleneck(self.pool(e4))\n        \n        # Decoder with attention\n        d4 = self.up(b)\n        e4_att = self.att4(d4, e4)\n        d4 = self.dec4(torch.cat([d4, e4_att], dim=1))\n        \n        d3 = self.up(d4)\n        e3_att = self.att3(d3, e3)\n        d3 = self.dec3(torch.cat([d3, e3_att], dim=1))\n        \n        d2 = self.up(d3)\n        e2_att = self.att2(d2, e2)\n        d2 = self.dec2(torch.cat([d2, e2_att], dim=1))\n        \n        d1 = self.up(d2)\n        e1_att = self.att1(d1, e1)\n        d1 = self.dec1(torch.cat([d1, e1_att], dim=1))\n        \n        return self.final(d1)\n\nmodel = UNetPlus(in_ch=6, out_ch=1, filters=(32,64,128,256,512)).to(DEVICE)\nprint(f\"Model params: {sum(p.numel() for p in model.parameters()):,}\")\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=7, verbose=True, min_lr=1e-6)\nearly_stop = EarlyStopping(patience=10, min_delta=1e-4)\n\nEPOCHS = 200\nhistory = []\n\nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss = 0.0\n    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Train\", leave=False):\n        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n        optimizer.zero_grad()\n        logits = model(xb)\n        loss = combined_loss(logits, yb)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        train_loss += loss.item() * xb.size(0)\n    train_loss /= len(train_loader.dataset)\n\n    model.eval()\n    val_loss = 0.0\n    agg = dict(tp=0,fp=0,fn=0,tn=0)\n    with torch.no_grad():\n        for xb, yb in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Val\", leave=False):\n            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n            logits = model(xb)\n            loss = combined_loss(logits, yb)\n            val_loss += loss.item() * xb.size(0)\n            mets = batch_metrics(logits, yb, thresh=0.5)\n            for k in agg: agg[k] += mets[k]\n    \n    val_loss /= len(val_loader.dataset)\n    eps=1e-8\n    tp,fp,fn,tn = agg['tp'],agg['fp'],agg['fn'],agg['tn']\n    iou = tp / (tp+fp+fn+eps)\n    dice = (2*tp)/(2*tp+fp+fn+eps)\n    precision = tp/(tp+fp+eps) if (tp+fp)>0 else 0\n    recall = tp/(tp+fn+eps) if (tp+fn)>0 else 0\n    f1 = 2*precision*recall/(precision+recall+eps) if (precision+recall)>0 else 0\n    acc = (tp+tn)/(tp+tn+fp+fn+eps)\n    history.append(dict(epoch=epoch+1, train_loss=train_loss, val_loss=val_loss, IoU=iou, Dice=dice, Precision=precision, Recall=recall, F1=f1, Accuracy=acc))\n\n    scheduler.step(val_loss)\n    print(f\"Epoch {epoch+1}: TL {train_loss:.4f} VL {val_loss:.4f} IoU {iou:.4f} Dice {dice:.4f} F1 {f1:.4f}\")\n\n    if epoch==0 or val_loss == min(h['val_loss'] for h in history):\n        torch.save(model.state_dict(), 'best_unetplus.pth')\n\n    if early_stop(epoch, val_loss, model):\n        print(f\"Early stopping at epoch {epoch+1}\")\n        break\n\npd.DataFrame(history).to_csv('training_history_unetplus.csv', index=False)\nprint('Training complete.')","metadata":{},"outputs":[],"execution_count":null},{"id":"3a4c6622","cell_type":"code","source":"# Test evaluation\nmodel = UNetPlus(in_ch=6, out_ch=1, filters=(32,64,128,256,512)).to(DEVICE)\nmodel.load_state_dict(torch.load('best_unetplus.pth', map_location=DEVICE))\nmodel.eval()\n\nagg = dict(tp=0,fp=0,fn=0,tn=0)\nall_preds = []\n\nwith torch.no_grad():\n    for xb, yb in tqdm(test_loader, desc=\"Test\", leave=False):\n        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n        logits = model(xb)\n        mets = batch_metrics(logits, yb, thresh=0.5)\n        for k in agg: agg[k] += mets[k]\n        probs = torch.sigmoid(logits)\n        preds = (probs>=0.5).float().cpu()\n        all_preds.append(preds)\n\nall_preds = torch.cat(all_preds, dim=0)\neps=1e-8\ntp,fp,fn,tn = agg['tp'],agg['fp'],agg['fn'],agg['tn']\niou = tp/(tp+fp+fn+eps)\ndice = (2*tp)/(2*tp+fp+fn+eps)\nprecision = tp/(tp+fp+eps) if (tp+fp)>0 else 0\nrecall = tp/(tp+fn+eps) if (tp+fn)>0 else 0\nf1 = 2*precision*recall/(precision+recall+eps) if (precision+recall)>0 else 0\nacc = (tp+tn)/(tp+tn+fp+fn+eps)\n\ncm = np.array([[tn, fp],[fn, tp]])\nmetrics = dict(IoU=iou, Dice=dice, Precision=precision, Recall=recall, F1=f1, Accuracy=acc, TP=tp, FP=fp, FN=fn, TN=tn)\n\nprint('\\nTest Metrics:')\nprint(f'IoU: {iou:.4f}')\nprint(f'Dice: {dice:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'F1: {f1:.4f}')\n\npd.DataFrame([metrics]).to_csv('test_metrics_unetplus.csv', index=False)\nnp.savetxt('confusion_matrix_unetplus.txt', cm, fmt='%d')\n\nos.makedirs('test_predictions_unetplus', exist_ok=True)\nfor i in range(min(10, all_preds.shape[0])):\n    img = (all_preds[i,0].numpy()*255).astype('uint8')\n    Image.fromarray(img).save(f'test_predictions_unetplus/pred_{i}.png')\nprint('Saved prediction samples.')","metadata":{},"outputs":[],"execution_count":null},{"id":"470dd56a","cell_type":"code","source":"# Visualization\nhist_df = pd.read_csv('training_history_unetplus.csv')\n\nfig, ((ax1, ax2, ax3),(ax4, ax5, ax6)) = plt.subplots(2,3, figsize=(16,8))\n\nax1.plot(hist_df['epoch'], hist_df['train_loss'], label='Train Loss', color='blue')\nax1.plot(hist_df['epoch'], hist_df['val_loss'], label='Val Loss', color='red')\nax1.set_title('Loss Curves')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\nax2.plot(hist_df['epoch'], hist_df['IoU'], label='IoU', color='green')\nax2.set_title('Validation IoU')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('IoU')\nax2.grid(True, alpha=0.3)\n\nax3.plot(hist_df['epoch'], hist_df['Dice'], label='Dice', color='orange')\nax3.set_title('Validation Dice')\nax3.set_xlabel('Epoch')\nax3.set_ylabel('Dice')\nax3.grid(True, alpha=0.3)\n\nax4.plot(hist_df['epoch'], hist_df['Precision'], label='Precision', color='purple')\nax4.plot(hist_df['epoch'], hist_df['Recall'], label='Recall', color='brown')\nax4.set_title('Precision & Recall')\nax4.set_xlabel('Epoch')\nax4.set_ylabel('Score')\nax4.legend()\nax4.grid(True, alpha=0.3)\n\nax5.plot(hist_df['epoch'], hist_df['F1'], label='F1', color='red')\nax5.plot(hist_df['epoch'], hist_df['Accuracy'], label='Accuracy', color='blue')\nax5.set_title('F1 & Accuracy')\nax5.set_xlabel('Epoch')\nax5.set_ylabel('Score')\nax5.legend()\nax5.grid(True, alpha=0.3)\n\nax6.axis('off')\nif len(hist_df) > 0:\n    best_epoch = hist_df.loc[hist_df['val_loss'].idxmin(), 'epoch']\n    best_val_loss = hist_df['val_loss'].min()\n    best_iou = hist_df['IoU'].max()\n    best_dice = hist_df['Dice'].max()\n    best_f1 = hist_df['F1'].max()\n    \n    summary_text = f\"\"\"\n    TRAINING SUMMARY\n    ================\n    Model: U-Net+\n    Total Epochs: {len(hist_df)}\n    Best Epoch: {best_epoch}\n    \n    Best Metrics:\n    Val Loss: {best_val_loss:.4f}\n    IoU: {best_iou:.4f}\n    Dice: {best_dice:.4f}\n    F1: {best_f1:.4f}\n    \"\"\"\n    ax6.text(0.1, 0.5, summary_text, fontsize=10, fontfamily='monospace',\n             verticalalignment='center', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n\nplt.tight_layout()\nplt.savefig('training_curves_unetplus.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"Visualization complete!\")","metadata":{},"outputs":[],"execution_count":null}]}